{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "kr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puj9cWxSgJ7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cae63a-4f1b-4200-f25a-fe82ec6279f1"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "static_back = None\n",
        "video = cv2.VideoCapture('55_trim.mp4')\n",
        "length = int (video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width = int (video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int (video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "kernel3 = np.ones((3,3),np.uint8)\n",
        "out = cv2.VideoWriter('ss.mp4', cv2.VideoWriter_fourcc(*'MP4V'),24.0,(width,height))\n",
        "\n",
        "k=0\n",
        "fr_b = None\n",
        "\n",
        "print(length)\n",
        "while (video.isOpened() and k < length):\n",
        "    k+=1\n",
        "    check,frame = video.read()\n",
        "    motion = 0\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    #gray = cv2.GaussianBlur(gray, (7,7),0)\n",
        "\n",
        "    if static_back is None:\n",
        "        static_back = gray\n",
        "        fr_b = gray\n",
        "        continue\n",
        "    else:\n",
        "        static_back = gray\n",
        "        \n",
        "            \n",
        "    \n",
        "    diff_frame = cv2.absdiff(static_back, fr_b)\n",
        "    fr_b = static_back\n",
        "    \n",
        "    thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh_frame = cv2.dilate(thresh_frame, None, iterations =10)\n",
        "    crops = []\n",
        "    kol_vo=0\n",
        "    #fgmask = fgbg.apply(thresh_frame)\n",
        "    cnts, _ = cv2.findContours(thresh_frame.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in cnts:\n",
        "        if cv2.contourArea(contour) > 1000000 or cv2.contourArea(contour) < 2500:\n",
        "            continue\n",
        "        \n",
        "        motion=1\n",
        "        kol_vo=kol_vo+1\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (155, 50, 165), 3)\n",
        "        crop = frame[y:y+h, x:x+w]\n",
        "        crops.append(crop)\n",
        "    #cv2.imshow('Color frame', frame)\n",
        "    #cv2.imshow('frame', frame)\n",
        "    thresh_frame = cv2.cvtColor(thresh_frame, cv2.COLOR_GRAY2RGB)\n",
        "    out.write(frame)\n",
        "    \n",
        "    #out.write(frame)\n",
        "\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF_V_9EbgJ7n",
        "outputId": "c8b74a4f-91f0-4997-cfff-d6f2e20ce7f2"
      },
      "source": [
        "import torch\n",
        "precision = 'fp32'\n",
        "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)\n",
        "#ssd_model =torch.load('tensors.pt', map_location=torch.device('cpu'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv6DbgfHgJ7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d285379-a63d-447a-e7b4-14309a41c8f4"
      },
      "source": [
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H1ISISnUwIp",
        "outputId": "8da91ab1-4ab3-4461-d9ab-436eff517f52"
      },
      "source": [
        "ssd_model.to('cuda')\n",
        "ssd_model.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SSD300(\n",
              "  (feature_extractor): ResNet(\n",
              "    (feature_extractor): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (additional_blocks): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (loc): ModuleList(\n",
              "    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (conf): ModuleList(\n",
              "    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiiz96Lhrd4_"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjb3Q4DODXdv"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "static_back = None\n",
        "video = cv2.VideoCapture('55_trim.mp4')\n",
        "length = int (video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width = int (video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int (video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "kernel3 = np.ones((3,3),np.uint8)\n",
        "out = cv2.VideoWriter('ss1.mp4', cv2.VideoWriter_fourcc(*'MP4V'),24.0,(width,height))\n",
        "\n",
        "k=0\n",
        "fr_b = None\n",
        "\n",
        "ii = 0\n",
        "while (video.isOpened() and k < length):\n",
        "    k+=1\n",
        "    check,frame = video.read()\n",
        "    motion = 0\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    if static_back is None:\n",
        "        static_back = gray\n",
        "        fr_b = gray\n",
        "        continue\n",
        "    else:\n",
        "        static_back = gray\n",
        "    diff_frame = cv2.absdiff(static_back, fr_b)\n",
        "    fr_b = static_back\n",
        "    \n",
        "    thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh_frame = cv2.dilate(thresh_frame, None, iterations =10)\n",
        "    crops = []\n",
        "    kol_vo=0\n",
        "    cnts, _ = cv2.findContours(thresh_frame.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    for contour in cnts:\n",
        "        if cv2.contourArea(contour) > 1000000 or cv2.contourArea(contour) < 2500:\n",
        "            continue\n",
        "        ii = ii + 1\n",
        "        motion=1\n",
        "        kol_vo=kol_vo+1\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (155, 50, 165), 3)\n",
        "        crop = frame[y:y+h, x:x+w]\n",
        "        path = \"crop\"+ str(ii) + \".jpg\"\n",
        "        cv2.imwrite(path, crop)\n",
        "        inputs = [utils.prepare_input(path)]\n",
        "        tensor = utils.prepare_tensor(inputs, precision == 'fp16')\n",
        "        with torch.no_grad():\n",
        "            detections_batch = ssd_model(tensor)\n",
        "        if ii!=221:\n",
        "          results_per_input = utils.decode_results(detections_batch)\n",
        "          best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
        "          classes_to_labels = utils.get_coco_object_dictionary()\n",
        "          bboxes, classes, confidences = best_results_per_input[0]\n",
        "          if len(classes) != 0:\n",
        "            a = classes[0]\n",
        "            if (a-1!=0):\n",
        "                cv2.putText(frame, \"not person\", (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "            else:\n",
        "              cv2.putText(frame, classes_to_labels[a-1], (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "          else:\n",
        "            cv2.putText(frame, \"not person\", (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "    thresh_frame = cv2.cvtColor(thresh_frame, cv2.COLOR_GRAY2RGB)\n",
        "    out.write(frame)\n",
        "\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwu3aLHTFbhB"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet152 \n",
        "model2 = ResNet152()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNHv-ij8FUb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b339ca-b818-42cf-8625-6c7d77291ecd"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "static_back = None\n",
        "video = cv2.VideoCapture('55_trim.mp4')\n",
        "length = int (video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width = int (video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int (video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "kernel3 = np.ones((3,3),np.uint8)\n",
        "out = cv2.VideoWriter('ss3.mp4', cv2.VideoWriter_fourcc(*'MP4V'),24.0,(width,height))\n",
        "kol_pers = 0\n",
        "k=0\n",
        "fr_b = None\n",
        "arr5 = []\n",
        "ii = 0\n",
        "while (video.isOpened() and k < length):\n",
        "    k+=1\n",
        "    check,frame = video.read()\n",
        "    motion = 0\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    #gray = cv2.GaussianBlur(gray, (7,7),0)\n",
        "\n",
        "    if static_back is None:\n",
        "        static_back = gray\n",
        "        fr_b = gray\n",
        "        continue\n",
        "    else:\n",
        "        static_back = gray\n",
        "        \n",
        "            \n",
        "    \n",
        "    diff_frame = cv2.absdiff(static_back, fr_b)\n",
        "    fr_b = static_back\n",
        "    \n",
        "    thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh_frame = cv2.dilate(thresh_frame, None, iterations =10)\n",
        "    crops = []\n",
        "    kol_vo=0\n",
        "    #fgmask = fgbg.apply(thresh_frame)\n",
        "    cnts, _ = cv2.findContours(thresh_frame.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    for contour in cnts:\n",
        "        if cv2.contourArea(contour) > 1000000 or cv2.contourArea(contour) < 2500:\n",
        "            continue\n",
        "        ii = ii + 1\n",
        "        motion=1\n",
        "        kol_vo=kol_vo+1\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (155, 50, 165), 3)\n",
        "        crop = frame[y:y+h, x:x+w]\n",
        "        path = \"crop\"+ str(ii) + \".jpg\"\n",
        "        cv2.imwrite(path, crop)\n",
        "        inputs = [utils.prepare_input(path)]\n",
        "        tensor = utils.prepare_tensor(inputs, precision == 'fp16')\n",
        "        with torch.no_grad():\n",
        "            detections_batch = ssd_model(tensor)\n",
        "        if ii!=221:\n",
        "          results_per_input = utils.decode_results(detections_batch)\n",
        "          best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
        "          classes_to_labels = utils.get_coco_object_dictionary()\n",
        "          bboxes, classes, confidences = best_results_per_input[0]\n",
        "          if len(classes) != 0:\n",
        "            a = classes[0]\n",
        "            if (a-1!=0):\n",
        "              if (a-1==16):\n",
        "                image = load_img(path, target_size=(224, 224))\n",
        "                image = img_to_array(image)\n",
        "                image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "                image = preprocess_input(image)\n",
        "                yhat = model2.predict(image)\n",
        "                from tensorflow.keras.applications.resnet import decode_predictions\n",
        "                label = decode_predictions(yhat)\n",
        "                label = label[0][0]\n",
        "                cv2.putText(frame, \"not person\", (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "                cv2.putText(frame, label[1], (x, y+h+30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
        "                arr5.append([\"cadr \" + str(k),x+w,y+h, \"not person\",label[1]])\n",
        "              else:\n",
        "                cv2.putText(frame, \"not person\", (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "                arr5.append([\"cadr \" + str(k),x+w,y+h, \"not person\"])\n",
        "            else:\n",
        "              cv2.putText(frame, classes_to_labels[a-1], (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "              kol_pers = kol_pers + 1\n",
        "              arr5.append([\"cadr \" + str(k),x+w,y+h, \"person\"])\n",
        "          else:\n",
        "            cv2.putText(frame, \"not person\", (x, y+h), cv2.FONT_HERSHEY_PLAIN, 1, (50, 60, 10), 2)\n",
        "            arr5.append([\"cadr \" + str(k),x+w,y+h, \"not person\"])\n",
        "    #cv2.imshow('Color frame', frame)\n",
        "    #cv2.imshow('frame', frame)\n",
        "    thresh_frame = cv2.cvtColor(thresh_frame, cv2.COLOR_GRAY2RGB)\n",
        "    out.write(frame)\n",
        "    \n",
        "    #out.write(frame)\n",
        "\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(arr5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['cadr 2', 250, 364, 'not person'], ['cadr 2', 106, 372, 'not person', 'Labrador_retriever'], ['cadr 2', 188, 302, 'person'], ['cadr 3', 251, 366, 'not person'], ['cadr 3', 102, 372, 'not person'], ['cadr 3', 188, 364, 'person'], ['cadr 4', 253, 367, 'not person'], ['cadr 4', 99, 371, 'not person'], ['cadr 4', 188, 358, 'not person'], ['cadr 5', 256, 366, 'not person'], ['cadr 5', 96, 373, 'not person', 'Labrador_retriever'], ['cadr 5', 189, 361, 'person'], ['cadr 6', 258, 367, 'not person'], ['cadr 6', 93, 373, 'not person', 'Labrador_retriever'], ['cadr 6', 189, 363, 'person'], ['cadr 7', 259, 370, 'not person'], ['cadr 7', 90, 372, 'not person', 'kuvasz'], ['cadr 7', 189, 363, 'person'], ['cadr 8', 261, 368, 'not person'], ['cadr 8', 87, 372, 'not person'], ['cadr 8', 188, 361, 'person'], ['cadr 9', 263, 368, 'not person'], ['cadr 9', 83, 373, 'not person'], ['cadr 9', 187, 366, 'person'], ['cadr 10', 265, 369, 'not person'], ['cadr 10', 79, 373, 'not person', 'Bedlington_terrier'], ['cadr 10', 186, 364, 'not person'], ['cadr 11', 267, 370, 'not person'], ['cadr 11', 76, 373, 'not person', 'kuvasz'], ['cadr 11', 189, 367, 'not person', 'tench'], ['cadr 12', 270, 370, 'not person'], ['cadr 12', 74, 374, 'not person', 'Labrador_retriever'], ['cadr 12', 189, 368, 'person'], ['cadr 13', 271, 371, 'not person'], ['cadr 13', 73, 374, 'not person', 'Labrador_retriever'], ['cadr 13', 189, 367, 'not person'], ['cadr 14', 274, 371, 'not person', 'German_shepherd'], ['cadr 14', 68, 373, 'not person', 'Labrador_retriever'], ['cadr 14', 188, 367, 'person'], ['cadr 15', 279, 371, 'not person'], ['cadr 15', 67, 372, 'not person'], ['cadr 15', 187, 367, 'person'], ['cadr 16', 66, 373, 'not person'], ['cadr 16', 278, 375, 'not person'], ['cadr 16', 186, 365, 'person'], ['cadr 17', 63, 374, 'not person'], ['cadr 17', 282, 375, 'not person', 'German_shepherd'], ['cadr 17', 185, 367, 'person'], ['cadr 18', 55, 374, 'not person'], ['cadr 18', 286, 377, 'not person', 'German_shepherd'], ['cadr 18', 184, 367, 'person'], ['cadr 19', 52, 374, 'not person'], ['cadr 19', 290, 377, 'not person', 'German_shepherd'], ['cadr 19', 184, 367, 'person'], ['cadr 20', 50, 376, 'not person'], ['cadr 20', 296, 377, 'not person', 'Australian_terrier'], ['cadr 20', 183, 368, 'person'], ['cadr 21', 302, 380, 'not person', 'Australian_terrier'], ['cadr 21', 185, 362, 'person'], ['cadr 22', 301, 383, 'not person'], ['cadr 22', 185, 367, 'person'], ['cadr 23', 302, 383, 'not person'], ['cadr 23', 181, 367, 'person'], ['cadr 24', 306, 375, 'not person', 'German_shepherd'], ['cadr 24', 183, 370, 'person'], ['cadr 25', 310, 381, 'not person', 'German_shepherd'], ['cadr 25', 183, 368, 'person'], ['cadr 26', 312, 384, 'not person', 'Chihuahua'], ['cadr 26', 183, 369, 'person'], ['cadr 27', 315, 381, 'not person', 'German_shepherd'], ['cadr 27', 176, 369, 'not person', 'ballplayer'], ['cadr 28', 319, 379, 'not person', 'German_shepherd'], ['cadr 28', 178, 370, 'not person'], ['cadr 29', 322, 389, 'not person', 'German_shepherd'], ['cadr 29', 186, 370, 'person'], ['cadr 30', 327, 387, 'not person'], ['cadr 30', 186, 370, 'person'], ['cadr 31', 331, 391, 'not person', 'German_shepherd'], ['cadr 31', 187, 370, 'person'], ['cadr 32', 336, 392, 'not person', 'German_shepherd'], ['cadr 32', 166, 311, 'person'], ['cadr 33', 344, 392, 'not person', 'German_shepherd'], ['cadr 33', 185, 369, 'person'], ['cadr 34', 349, 393, 'not person', 'German_shepherd'], ['cadr 34', 187, 368, 'person'], ['cadr 35', 357, 390, 'not person', 'German_shepherd'], ['cadr 35', 186, 369, 'not person', 'ballplayer'], ['cadr 36', 363, 401, 'not person', 'German_shepherd'], ['cadr 36', 186, 368, 'not person'], ['cadr 37', 362, 401, 'not person', 'German_shepherd'], ['cadr 37', 184, 367, 'person'], ['cadr 38', 368, 399, 'not person'], ['cadr 38', 183, 368, 'person'], ['cadr 39', 374, 396, 'not person'], ['cadr 39', 181, 369, 'person'], ['cadr 40', 379, 401, 'not person', 'German_shepherd'], ['cadr 40', 179, 370, 'person'], ['cadr 41', 384, 401, 'not person', 'German_shepherd'], ['cadr 41', 178, 371, 'person'], ['cadr 41', 766, 144, 'not person'], ['cadr 42', 50, 378, 'not person'], ['cadr 42', 388, 400, 'not person', 'German_shepherd'], ['cadr 42', 176, 371, 'person'], ['cadr 43', 52, 378, 'not person'], ['cadr 43', 393, 401, 'not person', 'German_shepherd'], ['cadr 43', 176, 369, 'person'], ['cadr 44', 398, 407, 'not person', 'German_shepherd'], ['cadr 44', 177, 373, 'person'], ['cadr 45', 404, 409, 'not person'], ['cadr 45', 177, 373, 'person'], ['cadr 46', 51, 378, 'not person'], ['cadr 46', 411, 412, 'not person', 'German_shepherd'], ['cadr 46', 177, 373, 'person'], ['cadr 47', 418, 411, 'not person', 'German_shepherd'], ['cadr 47', 176, 371, 'person'], ['cadr 48', 49, 378, 'not person'], ['cadr 48', 426, 410, 'not person'], ['cadr 48', 174, 374, 'person'], ['cadr 49', 52, 381, 'not person'], ['cadr 49', 435, 412, 'not person', 'German_shepherd'], ['cadr 49', 174, 371, 'person'], ['cadr 50', 52, 383, 'not person'], ['cadr 50', 458, 418, 'not person', 'German_shepherd'], ['cadr 50', 173, 372, 'person'], ['cadr 51', 51, 383, 'not person'], ['cadr 51', 462, 420, 'not person', 'German_shepherd'], ['cadr 51', 172, 370, 'person'], ['cadr 52', 48, 383, 'not person'], ['cadr 52', 470, 423, 'not person', 'German_shepherd'], ['cadr 52', 171, 370, 'person'], ['cadr 53', 52, 383, 'not person'], ['cadr 53', 474, 425, 'not person', 'German_shepherd'], ['cadr 53', 170, 370, 'person'], ['cadr 54', 52, 383, 'not person'], ['cadr 54', 485, 428, 'not person'], ['cadr 54', 170, 369, 'person'], ['cadr 55', 38, 383, 'not person'], ['cadr 55', 495, 428, 'not person'], ['cadr 55', 170, 370, 'person'], ['cadr 56', 39, 383, 'not person'], ['cadr 56', 504, 422, 'not person'], ['cadr 56', 172, 369, 'person'], ['cadr 57', 42, 383, 'not person'], ['cadr 57', 513, 425, 'not person'], ['cadr 57', 174, 372, 'person'], ['cadr 58', 41, 383, 'not person'], ['cadr 58', 523, 423, 'not person'], ['cadr 58', 176, 372, 'person'], ['cadr 59', 41, 383, 'not person'], ['cadr 59', 533, 433, 'not person', 'German_shepherd'], ['cadr 59', 178, 375, 'person'], ['cadr 60', 543, 435, 'not person', 'German_shepherd'], ['cadr 60', 176, 377, 'person'], ['cadr 61', 40, 383, 'not person'], ['cadr 61', 554, 439, 'not person', 'German_shepherd'], ['cadr 61', 177, 378, 'person'], ['cadr 62', 569, 441, 'not person', 'German_shepherd'], ['cadr 62', 180, 378, 'person'], ['cadr 63', 40, 386, 'not person'], ['cadr 63', 581, 442, 'not person', 'German_shepherd'], ['cadr 63', 174, 378, 'person'], ['cadr 64', 40, 384, 'not person'], ['cadr 64', 595, 434, 'not person', 'German_shepherd'], ['cadr 64', 175, 377, 'person'], ['cadr 65', 39, 384, 'not person'], ['cadr 65', 610, 439, 'not person', 'German_shepherd'], ['cadr 65', 178, 379, 'person'], ['cadr 66', 39, 387, 'not person'], ['cadr 66', 159, 378, 'not person'], ['cadr 66', 626, 442, 'not person', 'German_shepherd'], ['cadr 66', 180, 308, 'person'], ['cadr 67', 39, 388, 'not person'], ['cadr 67', 641, 450, 'not person', 'German_shepherd'], ['cadr 67', 180, 379, 'person'], ['cadr 68', 39, 389, 'not person'], ['cadr 68', 658, 452, 'not person', 'German_shepherd'], ['cadr 68', 179, 369, 'person'], ['cadr 69', 39, 388, 'not person'], ['cadr 69', 686, 457, 'not person', 'German_shepherd'], ['cadr 69', 179, 375, 'person'], ['cadr 70', 41, 385, 'not person'], ['cadr 70', 690, 462, 'not person', 'German_shepherd'], ['cadr 70', 177, 374, 'person'], ['cadr 71', 41, 384, 'not person'], ['cadr 71', 714, 465, 'not person', 'German_shepherd'], ['cadr 71', 175, 372, 'person'], ['cadr 72', 41, 389, 'not person'], ['cadr 72', 727, 466, 'not person'], ['cadr 72', 173, 375, 'person'], ['cadr 73', 41, 383, 'not person'], ['cadr 73', 746, 458, 'not person', 'German_shepherd'], ['cadr 73', 172, 376, 'person'], ['cadr 74', 41, 390, 'not person'], ['cadr 74', 766, 466, 'not person'], ['cadr 74', 173, 375, 'person'], ['cadr 75', 40, 391, 'not person'], ['cadr 75', 780, 469, 'not person'], ['cadr 75', 171, 378, 'person'], ['cadr 76', 38, 393, 'not person'], ['cadr 76', 780, 476, 'not person', 'German_shepherd'], ['cadr 76', 170, 380, 'person'], ['cadr 77', 38, 392, 'not person'], ['cadr 77', 780, 487, 'not person'], ['cadr 77', 170, 381, 'person'], ['cadr 78', 38, 391, 'not person'], ['cadr 78', 780, 483, 'not person'], ['cadr 78', 174, 382, 'person'], ['cadr 79', 38, 390, 'not person'], ['cadr 79', 780, 486, 'not person'], ['cadr 79', 171, 383, 'person'], ['cadr 80', 42, 391, 'not person'], ['cadr 80', 780, 488, 'not person'], ['cadr 80', 171, 383, 'person'], ['cadr 81', 40, 390, 'not person'], ['cadr 81', 780, 482, 'not person'], ['cadr 81', 170, 384, 'person'], ['cadr 82', 40, 390, 'not person'], ['cadr 82', 780, 476, 'not person'], ['cadr 82', 167, 384, 'person'], ['cadr 83', 41, 394, 'not person'], ['cadr 83', 707, 467, 'not person', 'German_shepherd'], ['cadr 83', 170, 379, 'person'], ['cadr 84', 41, 398, 'not person'], ['cadr 84', 780, 470, 'not person', 'German_shepherd'], ['cadr 84', 170, 383, 'person'], ['cadr 85', 40, 398, 'not person'], ['cadr 85', 780, 470, 'not person'], ['cadr 85', 171, 382, 'person'], ['cadr 86', 43, 398, 'not person'], ['cadr 86', 780, 480, 'not person'], ['cadr 86', 170, 380, 'person'], ['cadr 87', 44, 394, 'not person'], ['cadr 87', 780, 487, 'not person', 'German_shepherd'], ['cadr 87', 167, 380, 'person'], ['cadr 88', 45, 393, 'not person'], ['cadr 88', 780, 487, 'not person', 'German_shepherd'], ['cadr 88', 166, 379, 'person'], ['cadr 89', 47, 395, 'not person'], ['cadr 89', 780, 490, 'not person', 'German_shepherd'], ['cadr 89', 167, 380, 'person'], ['cadr 90', 49, 394, 'not person'], ['cadr 90', 780, 489, 'not person'], ['cadr 90', 192, 380, 'person']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL1Rb7psfksv",
        "outputId": "902be9e6-937d-45b6-e2d3-d291d06bcb4c"
      },
      "source": [
        "print(k)\n",
        "print(kol_pers)\n",
        "print((kol_pers/float(k))*100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90\n",
            "81\n",
            "90.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsWv9mBvValY"
      },
      "source": [
        "with open(\"log.txt\", \"w\") as file:\n",
        "    for  line in arr5:\n",
        "      for  l in line:\n",
        "        file.write(str(l) + \" \")\n",
        "      file.write('\\n')"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}